
\documentclass[a4paper,12pt]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{geometry}
\geometry{a4paper, margin=1in}

% Title and Author
\title{Machine Learning Experiments Report}
\author{AIML-10}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\newpage

% Abstract
\section*{Abstract}
\addcontentsline{toc}{section}{Abstract}
This report explores the impact of hyper-parameter tuning and sensory enhancement on the performance of the agents within the SoccerTwos environment of the ml-agents Unity package. We consider different configurations of hyper-parameters using policy loss, ELO and other metrics to identify optimal configurations, through hypothesis testing.


% Introduction
\section{Introduction}
There exist certain problems in computing that we cannot solve using simple programming techniques. Creating agents that are able to complete a task in a dynamic environment is one such problem. This can be addressed with machine learning algorithms. Machine learning is a branch of artificial intelligence that focuses on developing algorithms and models that enable systems to learn patterns and make predictions or decisions based on data. It allows models to adapt and improve through experience in unpredictable environments. Improving agents' performance has many utilities in real-life, such as in the field of robotics. 

The objective of this report is to explore ways to improve agent performance through hyper-parameter tuning and the addition of sensory models \cite{benoit2002fuzzy} that emulate human senses within SoccerTwos environment inside the Unity ML-Agents package \cite{unityTechnologies2019mlagents} \cite{ilosvay2024unity} \cite{juliani2018unity}.  Specifically we will examine how different sensor configurations affect the performance of the models by matching them up against each other. 

% Experiment
\section{Experiments}

\subsection{Past Work}
During our research, we developed certain scripts that improved the sensory capabilities of the agents, including a more realistic vision sensor and a sound sensor. While the basic ML-Agents package already contains a vision sensor, its implementation is somewhat unrealistic because the agent shoots vision rays from the back of its head and the vision cone is coupled to the rotation of the body. This means that the eyes can only point directly in front of the body, which is not a limitation in the real world. 

To address this, we implemented a vision system that enables agents to rotate their heads independently, allowing for a more flexible field of view. In addition,, the sound sensor works by detecting movement within a set distance from the agent. We set a low threshold that was applied to the velocity of all objects, when the velocity of the object exceeded it, the coordinates would be added to the memory of the agent. With our enhancements,the agents are now able to rotate their head and also hear sounds that are generated nearby. 
\newpage
\subsection{Hyper-Parameter Tuning}
To test the performance, and capacity for improvement, of the agents we performed two types of tests. The first test would be performed on the basic version of the Agent. We decided on five different hyper-parameters from the configuration file that we believed would yield interesting results if altered. For each hyper-parameter we picked four different values, two of them higher and two of them lower than the basic values, and trained a model to 2.5 million steps while only changing one value at a time. When we finished training the models we used a mathematical formula !!!TALK MORE ABOUT THE FORMULA!!! to decide which two of the five values were the best while taking into consideration the ELO, policy loss, cumulative reward and value loss, using the tensorboard module on the tfevent files. Using the two best values of each hyper-parameter we created exhaustive combinations, and trained the models accordingly. With all the results computed we wanted to test how !!! TALK ABOUT THE HYPOTHESIS TEST !!!

To find the best hyper-parameter configuration we had to choose between Grid Search, Random Search and an Evolutionary Algorithm, as our main method. We chose Grid Search because it provides a comprehensive overview of the hyper-parameter space. While it is computationally complex, we are able to draw meaningful results from the output, and it is also able to find the optimal configuration within the selection. This aligns with our goal of evaluating how each parameter affects the others.

While Random Search is generally more time-efficient than Grid Search, its reliance on randomness means that we are not able to derive any meaningful insights about the importance of certain hyper-parameters, without  extensive testing. With the computational constraints of our hardware, Random Search was not a method that we could use. 

Evolutionary Algorithms offer a promising balance between computational efficiency and mathematical rigor. However the complexity and time investment of developing one such algorithm ourselves caused us not to pursue it. Given the scope of this project, the implementation would take away from the goals we set out to accomplish.


\subsection{Comparison of Basic and Enhanced Agents}
In the second experiment we put the basic and enhanced agents in an environment and, using the same hyper-parameter configuration, we tested which one would perform better at the task.


\subsection{Values}
\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{Configurations} & \textbf{Batch\_Size} & \textbf{Learning\_Rate} & \textbf{Hidden\_Units} & \textbf{Beta} & \textbf{Lambda} \\
\hline
Value 1 & 512   & 0.00007 & 128   & 0.0012 & 0.9   \\
Value 2 & 1024  & 0.0001  & 256   & 0.0025 & 0.925 \\
Baseline & 2048  & 0.0003  & 512   & 0.005  & 0.95  \\
Value 3 & 3096  & 0.0005  & 768   & 0.01   & 0.975 \\
Value 4 & 4120  & 0.0012  & 1024  & 0.02   & 1     \\
\hline
\end{tabular}
\caption{Hyper-parameter configurations for agent training.}
\end{table}

% Results
\section{Results}

\section{Conclusions}
\newpage
% Resources
\section{Appendix}
\begin{table}[h!]
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{Config} & \textbf{Hidden\_Units} & \textbf{Beta} & \textbf{Learning\_Rate} & \textbf{Lambda} & \textbf{Batch\_Size} \\
\hline
1  & 256 & 0.0025 & 0.0003 & 0.925 & 4120 \\
2  & 256 & 0.0025 & 0.0003 & 0.925 & 1024 \\
3  & 256 & 0.0025 & 0.0003 & 0.9   & 4120 \\
4  & 256 & 0.0025 & 0.0003 & 0.9   & 1024 \\
5  & 256 & 0.0025 & 0.0012       & 0.925 & 4120 \\
6  & 256 & 0.0025 & 0.0012       & 0.925 & 1024 \\
7  & 256 & 0.0025 & 0.0012       & 0.9   & 4120 \\
8  & 256 & 0.0025 & 0.0012       & 0.9   & 1024 \\
9  & 256 & 0.01   & 0.003        & 0.925 & 4120 \\
10 & 256 & 0.01   & 0.003        & 0.925 & 1024 \\
11 & 256 & 0.01   & 0.003        & 0.9   & 4120 \\
12 & 256 & 0.01   & 0.0003       & 0.9   & 1024 \\
13 & 256 & 0.01   & 0.0012       & 0.925 & 4120 \\
14 & 256 & 0.01   & 0.0012       & 0.925 & 1024 \\
15 & 256 & 0.01   & 0.0012       & 0.9   & 4120 \\
16 & 256 & 0.01   & 0.0012       & 0.9   & 1024 \\
17 & 512 & 0.0025 & 0.0003       & 0.925 & 4120 \\
18 & 512 & 0.0025 & 0.0003       & 0.925 & 1024 \\
19 & 512 & 0.0025 & 0.0003       & 0.9   & 4120 \\
20 & 512 & 0.0025 & 0.0003       & 0.9   & 1024 \\
21 & 512 & 0.0025 & 0.0012       & 0.925 & 4120 \\
22 & 512 & 0.0025 & 0.0012       & 0.925 & 1024 \\
23 & 512 & 0.0025 & 0.0012       & 0.9   & 4120 \\
24 & 512 & 0.0025 & 0.0012       & 0.9   & 1024 \\
25 & 512 & 0.01   & 0.0003 & 0.925 & 4120 \\
26 & 512 & 0.01   & 0.0003 & 0.925 & 1024 \\
27 & 512 & 0.01   & 0.0003       & 0.9   & 4120 \\
28 & 512 & 0.01   & 0.0003       & 0.9   & 1024 \\
29 & 512 & 0.01   & 0.0012       & 0.925 & 4120 \\
30 & 512 & 0.01   & 0.0012       & 0.925 & 1024 \\
31 & 512 & 0.01   & 0.0012       & 0.9   & 4120 \\
32 & 512 & 0.01   & 0.0012       & 0.9   & 1024 \\
\hline
\end{tabular}
\caption{Detailed configurations used for hyper-parameter tuning experiments.}
\end{table}


% References
\addcontentsline{toc}{section}{References}
\bibliographystyle{plain}
\bibliography{references}  % Create a separate references.bib file for citations

\end{document}
